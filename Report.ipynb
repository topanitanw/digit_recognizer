{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1>EECS 475 Project: Handwritten Digit Classification </h1> </center>\n",
    "<center> <h3> <i>Panitan Wongse-ammat and Anh Le</i> </h3> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this project, we apply some machine learning algorithms to classify the hand-written digits. Our goal is to obtain at least 97% classification accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "We are well aware that this project has a few useful tutorials to read, and there are many ways to classify such data. We would like to make it more challenging by not only applying the techniques we have learned in class but also setting the accuracy baseline to be quite high enough to beat. Besides, we are excited to learn computer vision techniques and redraw images from such data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "The data for this project is downloaded from the famous <a href=\"http://yann.lecun.com/exdb/mnist/\" target=\"_blank\">MNIST</a> database. The data are separated to training data and testing data. Training data has 60000 data points each contains a gray-scale image of an hand-written digit from 0 to 9. Each image is an array of the size $28 \\times 28$ where each entry represents a pixel which has value in the range $0$ to $255$. The higher the value, the darker the pixel. The testing data has 10000 data points and is in the same format as the training data. Here is a sample of 10 images.\n",
    "<img src=\"image.png\">\n",
    "\n",
    "There are pre-written Python modules that pull MNIST data. However we decide to write our own data parsing that parses data directly from downloaded files from MNIST. In the attached notebook named \"parsing_data\", we write functions to take the raw data from MNIST, and dump the parsed data to two CSV files \"traindata\" and \"testdata\". \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "For better classification accurary, we implement two techniques to preprocess the data before feeding to the classification algorithms.\n",
    "<ul>\n",
    "    <li> Edge-based feature extraction</li>\n",
    "    <li> Scaling data by dividing each image by the largest pixel value</li>\n",
    "</ul>\n",
    "After using those two techniques, we see a huge improvement in accuracy. For example, in case of Supported Vector Machine (SVM), with raw data, we get 11% accuracy. That is almost as bad as random prediction. However, after normalizing the data, the accuracy jumps to 94%. Using edgebased tranformation, we get 97.8%. Similarly, in the case of K-nearest neighbor, with raw data, we get 40.3% accuracy. After using edgebased tranformation, this number jumps to 98.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "The following table lists all algorithms we implement for our classification job. We refer reader to the attached notebooks to see the detailed implementation. Here we only summarize the highest accuracy obtained corresponding to each algorithm. \n",
    "\n",
    "| Algorithm | Jupyter notebook name |Highest accuracy\n",
    "| --- | --- | --- |\n",
    "|Multiclass Perceptron|multiclass_perceptron_raw_pixel <br> multiclass_perceptron_edge_base| 97.8%\n",
    "|OvA|OvA_perceptron_raw_pixel <br> OvA_perceptron_edge_base| 86.9%\n",
    "|SVM|svm_raw_pixel <br> svm_edge_base|97.8%\n",
    "|Deep Learning| deep_learning_raw_pixel <br> deep_learning_edge_base|98.5%\n",
    "|K-Nearest Neighbor| k-nearest-raw<br> k-nearest-edge-based|98.5%\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "We obtain the initial goal of 97% of classification accuracy. To be precise, the best number we get is 98.5% in the cases of Deep Learning and K-Nearest Neighbor. This project helps us deepen our understanding of classification techiniques learned in class and motivate us to learn more techniques. Lastly, seeing the jump in accuracy after pre-processing the data, we see the importance of feature-engineering. Some time, a simple tweak in the data makes a huge difference at classification result. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
